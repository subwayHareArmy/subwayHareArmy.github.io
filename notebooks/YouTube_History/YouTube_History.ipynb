{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "YouTube History.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "biwlJ1AJmCxY",
        "colab_type": "code",
        "outputId": "13dc8f53-c24e-4f9b-91b7-80f840c0adfd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjTGBdf8mMmr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = \"/content/gdrive/My Drive/\"\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVSlnRmcmfJG",
        "colab_type": "code",
        "outputId": "3886f6b6-e199-472d-c19f-64dfb8701ec8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "source": [
        "yt = pd.read_csv(path + 'history_15_4_2020.csv') \n",
        "yt"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>vid</th>\n",
              "      <th>author_id</th>\n",
              "      <th>title</th>\n",
              "      <th>description</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>/watch?v=UvSwhTJtoDw</td>\n",
              "      <td>/channel/UCBH-aPeBFblv4G2uHgby2Sw</td>\n",
              "      <td>twenty one pilots Heathens Bass Cover with tab</td>\n",
              "      <td>twenty one pilots Heathens (from Suicide Squad...</td>\n",
              "      <td>194</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>/watch?v=oMDYlXuPOag</td>\n",
              "      <td>/channel/UCYb6YWTBfD0EB53shkN_6vA</td>\n",
              "      <td>Sharing Your Scraping Results in the Datasets ...</td>\n",
              "      <td>Scrapinghub's Datasets Catalog (https://app.sc...</td>\n",
              "      <td>113</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>/watch?v=Wh0NbbL1WhE</td>\n",
              "      <td>/channel/UCYb6YWTBfD0EB53shkN_6vA</td>\n",
              "      <td>How to Deploy Project Dependencies to Scrapy C...</td>\n",
              "      <td>The python ecosystem is awesome and chances ar...</td>\n",
              "      <td>102</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>/watch?v=JYch0zRmcgU</td>\n",
              "      <td>/channel/UCYb6YWTBfD0EB53shkN_6vA</td>\n",
              "      <td>How to Deploy a Scrapy Project to Scrapy Cloud</td>\n",
              "      <td>In this tutorial we show to deploy a Scrapy we...</td>\n",
              "      <td>148</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>/watch?v=G9Nni6G-iOc&amp;t=86s</td>\n",
              "      <td>/channel/UCYb6YWTBfD0EB53shkN_6vA</td>\n",
              "      <td>Following Pagination Links with Scrapy</td>\n",
              "      <td>This is the fourth video of the \"Learn Scrapy\"...</td>\n",
              "      <td>352</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19335</th>\n",
              "      <td>19336</td>\n",
              "      <td>/watch?v=UCZVSr2Xt2k</td>\n",
              "      <td>/user/bgfilms</td>\n",
              "      <td>Binging with Babish: Flanders' Hot Chocolate f...</td>\n",
              "      <td>Ned Flanders might be an uncomfortable source ...</td>\n",
              "      <td>174</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19336</th>\n",
              "      <td>19337</td>\n",
              "      <td>/watch?v=k_9P9GRqGcs</td>\n",
              "      <td>/user/chefsteps</td>\n",
              "      <td>Baked Beans Recipe • ChefSteps</td>\n",
              "      <td>Put down the can opener—our Baked Beans are th...</td>\n",
              "      <td>69</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19337</th>\n",
              "      <td>19338</td>\n",
              "      <td>/watch?v=MjBMUQNH90c&amp;t=3s</td>\n",
              "      <td>/user/robjnixon</td>\n",
              "      <td>How to make Baked Beans</td>\n",
              "      <td>Please Subscribe, it's free! - http://goo.gl/z...</td>\n",
              "      <td>241</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19338</th>\n",
              "      <td>19339</td>\n",
              "      <td>/watch?v=dRBPrdmwKBA</td>\n",
              "      <td>/channel/UCyE4_avlyfWBavfIQQ-8c4A</td>\n",
              "      <td>Calvin Harris - Hard To Love (ft. Jessie Reyez...</td>\n",
              "      <td>Hi guys!Here's our version of Hard To Love by ...</td>\n",
              "      <td>213</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19339</th>\n",
              "      <td>19340</td>\n",
              "      <td>/watch?v=gZFkp_LxTAs</td>\n",
              "      <td>/channel/UCyE4_avlyfWBavfIQQ-8c4A</td>\n",
              "      <td>Mad About You - Hooverphonic - Cover by Aditi ...</td>\n",
              "      <td>Hello!This song, originally by Hooverphonic, g...</td>\n",
              "      <td>209</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>19340 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          id  ... time\n",
              "0          1  ...  194\n",
              "1          2  ...  113\n",
              "2          3  ...  102\n",
              "3          4  ...  148\n",
              "4          5  ...  352\n",
              "...      ...  ...  ...\n",
              "19335  19336  ...  174\n",
              "19336  19337  ...   69\n",
              "19337  19338  ...  241\n",
              "19338  19339  ...  213\n",
              "19339  19340  ...  209\n",
              "\n",
              "[19340 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjNNq89kmitv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Making a dict of channels and their individual frequencies\n",
        "\n",
        "channels = list(set(list(yt['author_id'])))\n",
        "#ch_dct2 = {channels[i]: list(yt['author_id']).count(channels[i]) for i in range(0, len(channels))} \n",
        "\n",
        "ch_dct = {}\n",
        "\n",
        "for _ in range(0, len(list(yt['author_id']))):\n",
        "  channel = yt['author_id'][_]\n",
        "  try:\n",
        "    ch_dct[channel] = ch_dct[channel] + 1\n",
        "  except:\n",
        "    ch_dct[channel] = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92ly9dLNms72",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Making a dict of vids and their individual frequencies.\n",
        "\n",
        "vids = list(set(list(yt['vid'])))\n",
        "#ch_dct2 = {vids[i]: list(yt['vid']).count(vids[i]) for i in range(0, len(vids))} \n",
        "\n",
        "vid_dct = {}\n",
        "\n",
        "for _ in range(0, len(list(yt['vid']))):\n",
        "  vid = yt['vid'][_]\n",
        "  try:\n",
        "    vid_dct[vid] = vid_dct[vid] + 1\n",
        "  except:\n",
        "    vid_dct[vid] = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEHjw6v5m3c9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Making a dict of descriptions and their individual frequencies.\n",
        "\n",
        "descriptions = list(set(list(yt['description'])))\n",
        "#des_dct2 = {descriptions[i]: list(yt['description']).count(descriptions[i]) for i in range(0, len(descriptions))} \n",
        "\n",
        "des_dct = {}\n",
        "\n",
        "for _ in range(0, len(list(yt['description']))):\n",
        "  description = yt['description'][_]\n",
        "  try:\n",
        "    des_dct[description] = des_dct[description] + 1\n",
        "  except:\n",
        "    des_dct[description] = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KA6egFB5nCnD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Computing time \n",
        "\n",
        "watch_secs = sum(list(yt['time']))\n",
        "watch_hours = watch_secs/3600\n",
        "watch_days = watch_hours/24"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khbLKPdvnFCT",
        "colab_type": "code",
        "outputId": "9ef4725f-a9c4-45ee-80d9-8101f49ddf4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        }
      },
      "source": [
        "print(\"I have watched over \" + str(len(list(yt['id']))) + \" videos.\")\n",
        "print(\"Going through URLs for all videos watched, we find that of these \" + str(len(list(yt['id']))) + \" videos, \" + str(len(set(list(yt['vid'])))) + \" have been unique videos, and \" + str(len(list(yt['id'])) - len(set(list(yt['vid'])))) + \" have been repeats.\" )\n",
        "print(\"However, if we check for repeats by scanning throught the names of the videos, we find that of all the \" + str(len(list(yt['id']))) + \" videos, \" + str(len(list(set(list(yt['title']))))) + \" have been unique videos and \" + str(len(list(yt['title'])) - len(list(set(list(yt['title']))))) + \" have been repeats.\" )\n",
        "print(\"Further, if we check for repeats by scanning throught the descriptions of the videos, we find that of all the \" + str(len(list(yt['id']))) + \" videos, \" + str(len(list(set(list(yt['description']))))) + \" have been unique videos and \" + str(len(list(yt['description'])) - len(list(set(list(yt['description']))))) + \" have been repeats.\" )\n",
        "print(\"I have watched videos from over \" + str(len(ch_dct)) + \" channels.\" )\n",
        "print(\"My total watch time is \" + \"{:.0f}\".format(watch_secs) + \" seconds, \" + \"{:.2f}\".format(watch_hours) + \" hours, or \" \"{:.2f}\".format(watch_days) + \" days.\")\n",
        "print(\"This translates to around ~\" + \"{:.2f}\".format(100* (watch_days/(365*22))) + \"% of my life.\")\n",
        "\n"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I have watched over 19340 videos.\n",
            "Going through URLs for all videos watched, we find that of these 19340 videos, 12271 have been unique videos, and 7069 have been repeats.\n",
            "However, if we check for repeats by scanning throught the names of the videos, we find that of all the 19340 videos, 11755 have been unique videos and 7585 have been repeats.\n",
            "Further, if we check for repeats by scanning throught the descriptions of the videos, we find that of all the 19340 videos, 11015 have been unique videos and 8325 have been repeats.\n",
            "I assume that \n",
            "This would mean that, \n",
            "I have watched videos from over 5368 channels.\n",
            "My total watch time is 9899651 seconds, 2749.90 hours, or 114.58 days.\n",
            "This translates to around ~1.43% of my life.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}